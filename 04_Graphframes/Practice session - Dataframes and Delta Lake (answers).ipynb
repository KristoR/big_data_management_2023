{"cells":[{"cell_type":"markdown","source":["#### Task\n\nEmployees' dataset: \"/mnt/training/manufacturing-org/employees/employees.csv\"\n\nUsing window functions, find the **employees** who have worked in a specific **department** the *longest* and *shortest* time.\n\nResulting dataframe should have 3 columns: employee_name, department, employment_duration\n\nEmployment_duration should have 2 possible values: \n* **longest**\n  * The employee has worked in the department for the longest time. Based on column _active_record_start_\n* **shortest**\n  * The employee has worked in the department for the shortest time. Based on column _active_record_start_\n\nDataframe should have total 6 rows.\n\nExample df.take(3):</br>\n<table>\n  <tr>\n    <th>employee_name</th>\n    <th>department</th>\n    <th>employment_duration</th>\n  </tr>\n  <tr>\n    <td>CISNEROS JR, HERBERT</td>\n    <td>OFFICE</td>\n    <td>shortest</td>\n  </tr>\n  <tr>\n    <td>CRAVEN, KEVIN J</td>\n    <td>OFFICE</td>\n    <td>longest</td>\n  </tr>\n  <tr>\n    <td>WRIGHT, RONALD G</td>\n    <td>PRODUCTION</td>\n    <td>shortest</td>\n  </tr>\n</table>\n\nNote: highest points are awarded to solutions where dataframe has least transformations.</br>\nShould be doable with 2 window functions and 2 transformations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a57b17c3-5757-49ad-a6bb-d3838da3d183"}}},{"cell_type":"code","source":["# we need to import the Window API and instantiate a Window specification object\n# let's also import pyspark.sql.functions for using aggregations and functions  \n\nimport pyspark.sql.functions as F\nfrom pyspark.sql import Window\n\ndf = spark.read.csv(\"/mnt/training/manufacturing-org/employees/employees.csv\", header=True, inferSchema=True)\n\nwindow_spec = Window.partitionBy(\"department\").orderBy(\"active_record_start\")\nwindow_spec_desc = Window.partitionBy(\"department\").orderBy(F.desc(\"active_record_start\"))\n\ndisplay(df\n       .withColumn(\"oldest\", F.row_number().over(window_spec)) \n       .withColumn(\"newest\", F.row_number().over(window_spec_desc))\n       .filter((F.col(\"newest\") == 1) | (F.col(\"oldest\") == 1))\n       .selectExpr(\"employee_name\", \"department\", \"case when oldest = 1 then 'longest' when newest = 1 then 'shortest' else null end employment_duration\")\n       )\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"942cee83-1c5f-4227-99e3-82f103c8430b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Practice session - Dataframes and Delta Lake (answers)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":660834880574601}},"nbformat":4,"nbformat_minor":0}
