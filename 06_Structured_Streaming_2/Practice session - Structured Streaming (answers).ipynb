{"cells":[{"cell_type":"markdown","source":["#### Task\n\nCreate a schema and a streaming dataframe for the JSON files in the following path:  \n\"/mnt/training/gaming_data/mobile_streaming_events_b/\"\n  \n  \nUse the following as basis for creating your schema:  \n |-- eventName: string (nullable = true)  \n |-- eventParams: struct (nullable = true)  \n |    |-- amount: double (nullable = true)  \n |    |-- app_name: string (nullable = true)  \n |    |-- app_version: string (nullable = true)  \n |    |-- client_event_time: string (nullable = true)  \n |    |-- device_id: string (nullable = true)  \n |    |-- game_keyword: string (nullable = true)  \n |    |-- platform: string (nullable = true)  \n |    |-- scoreAdjustment: long (nullable = true)  \n  \nRead in 2 files per trigger.\n  \nCreate a new modified dataframe:\n* keep only rows where eventName is \"scoreAdjustment\"\n* select the *game_keyword*, *platform* and *scoreAdjustment* columns from the eventParams struct.  \n* set trigger to run every 5 seconds.\n\nWrite the datastream to a delta table called score_adjustments.  \nCheck to make sure that the table has some data.  \nThen stop the datastream."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5529e151-580d-4423-9abd-8fe088b33c2e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.types import *\nschema = StructType([\n  StructField('eventName', StringType(), True), \n  StructField('eventParams', StructType([\n    StructField('amount', DoubleType(), True), \n    StructField('app_name', StringType(), True), \n    StructField('app_version', StringType(), True), \n    StructField('client_event_time', StringType(), True), \n    StructField('device_id', StringType(), True), \n    StructField('game_keyword', StringType(), True), \n    StructField('platform', StringType(), True), \n    StructField('scoreAdjustment', LongType(), True)\n  ]), True)\n])\n\ndf = (spark.readStream\n      .schema(schema)\n      .option(\"maxFilesPerTrigger\", 2) \n      .json(\"/mnt/training/gaming_data/mobile_streaming_events_b/\")\n     )\n\nnewdf = (df\n         .filter(\"eventName == 'scoreAdjustment'\")\n         .select(\"eventParams.game_keyword\", \"eventParams.platform\", \"eventParams.scoreAdjustment\")\n        )\n\n(newdf.writeStream\n  .format(\"delta\")\n  .outputMode(\"append\")\n  .trigger(processingTime=\"5 second\") \n  .option(\"checkpointLocation\", \"/tmp/score_adjustments/_checkpoints/\")\n  .table(\"score_adjustments\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1cb00d9a-0dbe-4463-8437-6a0f21413569","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.table(\"score_adjustments\").count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6838942d-aed0-4fc2-8f30-9db1c4062292","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for stream in spark.streams.active:\n  stream.stop()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f882ddbb-8e6f-48af-a8f8-d86a1e704f79","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Practice session - Structured Streaming (answers)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2687514412223135}},"nbformat":4,"nbformat_minor":0}
